import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as p,c as t,f as o}from"./app-CahC9Ikc.js";const e={},a=o('<h1 id="非-prompt-大模型优化技巧" tabindex="-1"><a class="header-anchor" href="#非-prompt-大模型优化技巧" aria-hidden="true">#</a> 非 Prompt 大模型优化技巧</h1><h2 id="轮询" tabindex="-1"><a class="header-anchor" href="#轮询" aria-hidden="true">#</a> 轮询</h2><p>大模型给出的结果存在浮动，并且对于通用的大模型基座，单个 Prompt 执行正确率也存在一定的上限，故在达到 90% 的阈值之后，在 Prompt 层面的继续优化对最终正确率的提升可能并不显著。</p><p>并且，即使是一个非常优异的 Prompt，也会因为大模型基座的迭代而发生正确率的震荡，这是非常不稳定且不值得的，于是我们可以从 Prompt 之外的地方寻求正确率和稳定性的提升。</p><p>一个效果比较显著的方式是通过“轮询”的方式，用通俗的话来说，就是轮流尝试多个 Prompt 方案。</p><p>比如当前存在 A、B、C 三种 Prompt 方案，我们可以先尝试 A 方案，如果失败了再依次尝试 B、C 方案。</p><p>这样的方法可以综合提升整体 Prompt 的成功率，其原因在于并不存在一个绝对最优的 Prompt，有一些在单独测试的时候正确率较低的 Prompt 方案，也能解决一些“更优方案”覆盖不到的 case。</p><p>故我们综合多种 Prompt 方案，通过轮询的方式，可以达到更高的正确率，并且对于大模型基座的迭代也具有更强的适应性，通常能够达到 95% 以上的正确率。</p><h2 id="大小问" tabindex="-1"><a class="header-anchor" href="#大小问" aria-hidden="true">#</a> 大小问</h2><p>有时候我们希望通过大模型解决的问题，其实包含了若干个子问题，比如我们希望大模型向我们介绍一个人，实际上包含了 A、B、C 等需要解决的小问题，比如人的姓名、人的性别、人的经历等，我们可以在 Promt 中为大模型指明如何获取各个部分的信息，但是限制于 Prompt 的正确率，我们可能会得到一些错误的信息，即大模型幻觉。</p><p>而对于问题的某一些部分我们是不允许出现幻觉的，这些部分可能会影响到我们后续的操作，比如上面介绍一个人的例子中，人的性别、人的年龄是我们希望准确得到的信息，此时除了在 Prompt 上进一步优化之外，我们也可以通过“大小问”的方式，用通俗的话来讲，就是重要的事情单独问。</p><p>比如我希望确保返回的结果中存在 X 和 Y 方面的信息，那么我们可以先使用 A Promtp 方案去问一个大问题，得到一个整体的框架；再通过 B Promtp 方案问小问题，单独获取 X 方面的信息；再通过 C Prompt 方案单独获取 Y 方面的信息，以确保关键信息的获取，最后再通过小问题的答案去更新大问题答案。</p><p>大模型解决单一目标问题的正确率会显著高于解决复合问题的正确率。</p>',13),m=[a];function c(h,i){return p(),t("div",null,m)}const n=r(e,[["render",c],["__file","500_prompt_skill.html.vue"]]);export{n as default};
